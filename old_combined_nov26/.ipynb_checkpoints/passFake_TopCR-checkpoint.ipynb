{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6c4165-5d04-46d8-b6a3-beda838a2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "\n",
    "import hist as hist2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import yaml\n",
    "#from systematics import get_systematic_dict, sigs\n",
    "from systematicsPass import get_systematic_dict, sigs\n",
    "\n",
    "from utils import get_common_sample_name, get_finetuned_score, get_xsecweight\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "\n",
    "CATEGORY = 'pass'\n",
    "\n",
    "\n",
    "\n",
    "def get_templates(years, channels, samples, samples_dir, regions_sel, model_path, add_fake=False):\n",
    "\n",
    "    print('regions_sel', regions_sel)\n",
    "    # add extra selections to preselection\n",
    "    presel = { \"mu\": { \"fj_mass\": \"fj_mass < 180\",}, \"ele\": {\"fj_mass\": \"fj_mass <180\",}, }\n",
    "\n",
    "\n",
    "    region = 'TopCR'\n",
    "    mass_binning = [40,70,120,180]\n",
    "\n",
    "    \n",
    "    hists = hist2.Hist(\n",
    "        hist2.axis.StrCategory([], name=\"Sample\", growth=True), hist2.axis.StrCategory([], name=\"Systematic\", growth=True), hist2.axis.StrCategory([], name=\"Region\", growth=True),\n",
    "        hist2.axis.Variable(\n",
    "            #list(range(55, 255, mass_binning)),\n",
    "            mass_binning, name=\"mass_observable\", label=r\"V reconstructed mass [GeV]\", overflow=True,\n",
    "        ), storage=hist2.storage.Weight(),\n",
    "    )\n",
    "\n",
    "    for variation in [\"fakes_nominal\", \"fakes_SF_Up\", \"fakes_SF_Down\", \"fakes_DR_Up\", \"fakes_DR_Down\"]:\n",
    "   \n",
    "        for year in years:\n",
    "            data = pd.read_parquet(f\"/uscms/home/jieun201/nobackup/YOURWORKINGAREA/Fake_{year}/outfiles/{variation}_ele.parquet\")\n",
    "  \n",
    "            for selection in presel[\"ele\"]:\n",
    "                logging.info(f\"Applying {selection} selection on {len(data)} events\")\n",
    "                data = data.query(presel[\"ele\"][selection])\n",
    "                #data[\"THWW\"] = get_finetuned_score(data, model_path) #not using HWW score for top CR\n",
    "     \n",
    "            df = data.copy()\n",
    "       \n",
    "            df = df[ (df['numberBJets_Medium_OutsideFatJets'] > 0) & (df['ReconVCandidateFatJetVScore'] > 0.9)\n",
    "            & (df['met_pt'] > 30) & (df['fj_pt'] > 250) & (df['h_fj_pt'] > 250) ]\n",
    "                    \n",
    "            \n",
    "            logging.info(f\"Will fill the histograms with the remaining {len(data)} events\")\n",
    "\n",
    "            if variation == \"fakes_nominal\":\n",
    "                hists.fill( Sample=\"Fake\", Systematic=\"pass_nominal\", Region=region, mass_observable=df[\"fj_mass\"], weight=df[\"event_weight\"],  )\n",
    "            else:\n",
    "                print('variation', variation)\n",
    "                hists.fill( Sample=\"Fake\", Systematic=\"pass_\" + variation, Region=region, mass_observable=df[\"fj_mass\"], weight=df[\"event_weight\"],  )\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return hists\n",
    "\n",
    "\n",
    "def fix_neg_yields(h):\n",
    "    \"\"\"\n",
    "    Will set the bin yields of a process to 0 if the nominal yield is negative, and will\n",
    "    set the yield to 0 for the full Systematic axis.\n",
    "    \"\"\"\n",
    "    for region in h.axes[\"Region\"]:\n",
    "        for sample in h.axes[\"Sample\"]:\n",
    "            neg_bins = np.where(h[{\"Sample\": sample, \"Systematic\": \"pass_nominal\", \"Region\": region}].values() < 0)[0]\n",
    "\n",
    "            if len(neg_bins) > 0:\n",
    "                print('got neg bins')\n",
    "                print(f\"{region}, {sample}, has {len(neg_bins)} bins with negative yield.. will set them to 0\")\n",
    "\n",
    "                sample_index = np.argmax(np.array(h.axes[\"Sample\"]) == sample)\n",
    "                region_index = np.argmax(np.array(h.axes[\"Region\"]) == region)\n",
    "\n",
    "                for neg_bin in neg_bins:\n",
    "                    h.view(flow=True)[sample_index, :, region_index, neg_bin + 1].value = 1e-3\n",
    "                    h.view(flow=True)[sample_index, :, region_index, neg_bin + 1].variance = 1e-3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2676f130-3778-4ea2-b179-e9cf1f6423f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regions_sel {'TopCR': '(numberBJets_Medium_OutsideFatJets > 0) & (met_pt > 30) & (fj_pt > 250) & (h_fj_pt > 250)  & (ReconVCandidateFatJetVScore > 0.9)'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Applying fj_mass selection on 147477 events\n",
      "INFO:root:Will fill the histograms with the remaining 140917 events\n",
      "INFO:root:Applying fj_mass selection on 147477 events\n",
      "INFO:root:Will fill the histograms with the remaining 140917 events\n",
      "INFO:root:Applying fj_mass selection on 147477 events\n",
      "INFO:root:Will fill the histograms with the remaining 140917 events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variation fakes_SF_Up\n",
      "variation fakes_SF_Down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Applying fj_mass selection on 147477 events\n",
      "INFO:root:Will fill the histograms with the remaining 140917 events\n",
      "INFO:root:Applying fj_mass selection on 147477 events\n",
      "INFO:root:Will fill the histograms with the remaining 140917 events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variation fakes_DR_Up\n",
      "variation fakes_DR_Down\n",
      "got neg bins\n",
      "TopCR, Fake, has 3 bins with negative yield.. will set them to 0\n",
      "hists Hist(\n",
      "  StrCategory(['Fake'], growth=True, name='Sample'),\n",
      "  StrCategory(['pass_nominal', 'pass_fakes_SF_Up', 'pass_fakes_SF_Down', 'pass_fakes_DR_Up', 'pass_fakes_DR_Down'], growth=True, name='Systematic'),\n",
      "  StrCategory(['TopCR'], growth=True, name='Region'),\n",
      "  Variable([40, 70, 120, 180], name='mass_observable', label='V reconstructed mass [GeV]'),\n",
      "  storage=Weight()) # Sum: WeightedSum(value=0.015, variance=0.015)\n"
     ]
    }
   ],
   "source": [
    "#years = ['2017','2018']\n",
    "years = ['2017']\n",
    "\n",
    "#years = ['2016', '2016APV','2017', '2018']\n",
    "#years = ['2017', '2018']\n",
    "\n",
    "outdir = 'templates'\n",
    "\n",
    "channels = 'mu','ele'\n",
    "with open(\"simplePass_Fake_TopCR.yaml\", \"r\") as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "if len(years) == 4:\n",
    "    save_as = \"Run2\"\n",
    "else:\n",
    "    save_as = \"_\".join(years)\n",
    "\n",
    "if len(channels) == 1:\n",
    "    save_as += f\"_{channels[0]}_\"\n",
    "\n",
    "os.system(f\"mkdir -p {outdir}\")\n",
    "\n",
    "\n",
    "#def get_templates(years, channels, samples, samples_dir, regions_sel, model_path, add_fake=False):\n",
    "hists = get_templates( years, channels, 'Fake', config[\"samples_dir\"], config[\"regions_sel\"], config[\"model_path\"],)\n",
    "\n",
    "fix_neg_yields(hists)\n",
    "\n",
    "with open(f\"{outdir}/hists_templates_{save_as}_fake_pass_TopCR.pkl\", \"wb\") as fp:\n",
    "    print('hists', hists)\n",
    "    pkl.dump(hists, fp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af98e3c6-6270-46e3-91d6-36784af3b01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hist(\n",
       "  StrCategory(['Fake'], growth=True, name='Sample'),\n",
       "  StrCategory(['pass_nominal', 'pass_fakes_SF_Up', 'pass_fakes_SF_Down', 'pass_fakes_DR_Up', 'pass_fakes_DR_Down'], growth=True, name='Systematic'),\n",
       "  StrCategory(['TopCR'], growth=True, name='Region'),\n",
       "  Variable([40, 70, 120, 180], name='mass_observable', label='V reconstructed mass [GeV]'),\n",
       "  storage=Weight()) # Sum: WeightedSum(value=0.015, variance=0.015)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = pd.read_pickle(r'/home/jieun201/boostedhiggs_may27/combine/templates/hists_templates_2017_fake_pass_TopCR.pkl')\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58dc9cce-00ac-4eed-86af-2eb9b64022ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<div style=\"display:flex; align-items:center;\">\n",
       "<div style=\"width:290px;\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"-10 -105 270 120\">\n",
       "<line x1=\"-5\" y1=\"0\" x2=\"255\" y2=\"0\" style=\"fill:none;stroke-width:2;stroke:currentColor\"/>\n",
       "<text text-anchor=\"middle\" x=\"0\" y=\"15\" style=\"fill:currentColor;\">\n",
       "40\n",
       "</text>\n",
       "<text text-anchor=\"middle\" x=\"250\" y=\"15\" style=\"fill:currentColor;\">\n",
       "180\n",
       "</text>\n",
       "<text text-anchor=\"middle\" x=\"125.0\" y=\"15\" style=\"fill:currentColor;\">\n",
       "V reconstructed mass [GeV]\n",
       "</text>\n",
       "<polyline points=\"  0,0   0,-100 53.5714,-100 53.5714,-60 142.857,-60 142.857,-50 250,-50 250,0\" style=\"fill:none; stroke:currentColor;\"/>\n",
       "</svg>\n",
       "</div>\n",
       "<div style=\"flex=grow:1;\">\n",
       "Variable([40, 70, 120, 180], name='mass_observable', label='V reconstructed mass [GeV]')<br/>\n",
       "<hr style=\"margin-top:.2em; margin-bottom:.2em;\"/>\n",
       "Weight() Î£=WeightedSum(value=0.003, variance=0.003)\n",
       "\n",
       "</div>\n",
       "</div>\n",
       "</html>"
      ],
      "text/plain": [
       "Hist(Variable([40, 70, 120, 180], name='mass_observable', label='V reconstructed mass [GeV]'), storage=Weight()) # Sum: WeightedSum(value=0.003, variance=0.003)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakePass_3 = obj[{\"Region\": \"TopCR\", \"Sample\": \"Fake\", \"Systematic\": \"pass_nominal\"}]\n",
    "fakePass_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c24b48-a72d-4a1a-92c3-93b93eee2326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
