{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c4165-5d04-46d8-b6a3-beda838a2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "\n",
    "import hist as hist2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import yaml\n",
    "#from systematics import get_systematic_dict, sigs\n",
    "from systematicsPass import get_systematic_dict, sigs\n",
    "\n",
    "from utils import get_common_sample_name, get_finetuned_score, get_xsecweight\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "\n",
    "CATEGORY = 'pass'\n",
    "\n",
    "\n",
    "\n",
    "def get_templates(years, channels, samples, samples_dir, regions_sel, model_path, add_fake=False):\n",
    "\n",
    "    print('regions_sel', regions_sel)\n",
    "    # add extra selections to preselection\n",
    "    presel = { \"mu\": { \"fj_mass\": \"fj_mass < 180\",}, \"ele\": {\"fj_mass\": \"fj_mass <180\",}, }\n",
    "\n",
    "\n",
    "    region = 'TopCR'\n",
    "    mass_binning = [40,70,105,135,180]\n",
    "\n",
    "    \n",
    "    hists = hist2.Hist(\n",
    "        hist2.axis.StrCategory([], name=\"Sample\", growth=True), hist2.axis.StrCategory([], name=\"Systematic\", growth=True), hist2.axis.StrCategory([], name=\"Region\", growth=True),\n",
    "        hist2.axis.Variable(\n",
    "            #list(range(55, 255, mass_binning)),\n",
    "            mass_binning, name=\"mass_observable\", label=r\"V reconstructed mass [GeV]\", overflow=True,\n",
    "        ), storage=hist2.storage.Weight(),\n",
    "    )\n",
    "\n",
    "    for variation in [\"fakes_nominal\", \"fakes_SF_Up\", \"fakes_SF_Down\", \"fakes_DR_Up\", \"fakes_DR_Down\"]:\n",
    "   \n",
    "        for year in years:\n",
    "            data = pd.read_parquet(f\"/uscms/home/jieun201/nobackup/YOURWORKINGAREA/Fake_{year}/outfiles/{variation}_ele.parquet\")\n",
    "  \n",
    "            for selection in presel[\"ele\"]:\n",
    "                logging.info(f\"Applying {selection} selection on {len(data)} events\")\n",
    "                data = data.query(presel[\"ele\"][selection])\n",
    "                #data[\"THWW\"] = get_finetuned_score(data, model_path) #not using HWW score for top CR\n",
    "     \n",
    "            df = data.copy()\n",
    "       \n",
    "            df = df[ (df['numberBJets_Medium_OutsideFatJets'] > 0) & (df['ReconVCandidateFatJetVScore'] > 0.9)\n",
    "            & (df['met_pt'] > 30) & (df['fj_pt'] > 250) & (df['h_fj_pt'] > 250) ]\n",
    "                    \n",
    "            \n",
    "            logging.info(f\"Will fill the histograms with the remaining {len(data)} events\")\n",
    "\n",
    "            if variation == \"fakes_nominal\":\n",
    "                hists.fill( Sample=\"Fake\", Systematic=\"pass_nominal\", Region=region, mass_observable=df[\"fj_mass\"], weight=df[\"event_weight\"],  )\n",
    "            else:\n",
    "                print('variation', variation)\n",
    "                hists.fill( Sample=\"Fake\", Systematic=\"pass_\" + variation, Region=region, mass_observable=df[\"fj_mass\"], weight=df[\"event_weight\"],  )\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return hists\n",
    "\n",
    "\n",
    "def fix_neg_yields(h):\n",
    "    \"\"\"\n",
    "    Will set the bin yields of a process to 0 if the nominal yield is negative, and will\n",
    "    set the yield to 0 for the full Systematic axis.\n",
    "    \"\"\"\n",
    "    for region in h.axes[\"Region\"]:\n",
    "        for sample in h.axes[\"Sample\"]:\n",
    "            neg_bins = np.where(h[{\"Sample\": sample, \"Systematic\": \"pass_nominal\", \"Region\": region}].values() < 0)[0]\n",
    "\n",
    "            if len(neg_bins) > 0:\n",
    "                print('got neg bins')\n",
    "                print(f\"{region}, {sample}, has {len(neg_bins)} bins with negative yield.. will set them to 0\")\n",
    "\n",
    "                sample_index = np.argmax(np.array(h.axes[\"Sample\"]) == sample)\n",
    "                region_index = np.argmax(np.array(h.axes[\"Region\"]) == region)\n",
    "\n",
    "                for neg_bin in neg_bins:\n",
    "                    h.view(flow=True)[sample_index, :, region_index, neg_bin + 1].value = 1e-3\n",
    "                    h.view(flow=True)[sample_index, :, region_index, neg_bin + 1].variance = 1e-3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676f130-3778-4ea2-b179-e9cf1f6423f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#years = ['2017','2018']\n",
    "years = ['2018']\n",
    "\n",
    "#years = ['2016', '2016APV','2017', '2018']\n",
    "#years = ['2017', '2018']\n",
    "\n",
    "outdir = 'templates'\n",
    "\n",
    "channels = 'mu','ele'\n",
    "with open(\"simplePass_Fake_TopCR.yaml\", \"r\") as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "if len(years) == 4:\n",
    "    save_as = \"Run2\"\n",
    "else:\n",
    "    save_as = \"_\".join(years)\n",
    "\n",
    "if len(channels) == 1:\n",
    "    save_as += f\"_{channels[0]}_\"\n",
    "\n",
    "os.system(f\"mkdir -p {outdir}\")\n",
    "\n",
    "\n",
    "#def get_templates(years, channels, samples, samples_dir, regions_sel, model_path, add_fake=False):\n",
    "hists = get_templates( years, channels, 'Fake', config[\"samples_dir\"], config[\"regions_sel\"], config[\"model_path\"],)\n",
    "\n",
    "fix_neg_yields(hists)\n",
    "\n",
    "with open(f\"{outdir}/hists_templates_{save_as}_fake_pass_TopCR.pkl\", \"wb\") as fp:\n",
    "    print('hists', hists)\n",
    "    pkl.dump(hists, fp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98e3c6-6270-46e3-91d6-36784af3b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.read_pickle(r'/home/jieun201/boostedhiggs_may27/combine/templates/hists_templates_2018_fake_pass_TopCR.pkl')\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc9cce-00ac-4eed-86af-2eb9b64022ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fakePass_3 = obj[{\"Region\": \"TopCR\", \"Sample\": \"Fake\", \"Systematic\": \"pass_nominal\"}]\n",
    "fakePass_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c24b48-a72d-4a1a-92c3-93b93eee2326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
