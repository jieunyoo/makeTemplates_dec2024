{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6c4165-5d04-46d8-b6a3-beda838a2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "\n",
    "import hist as hist2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import yaml\n",
    "\n",
    "from systematicsPass import get_systematic_dict, sigs\n",
    "\n",
    "from utils import get_common_sample_name, get_finetuned_score, get_xsecweight\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "\n",
    "\n",
    "CATEGORY = 'pass'\n",
    "\n",
    "\n",
    "#2018 \n",
    "nom_trig = [  0.97316853, 1.00480192, 0.99773121, 1.00115747, 0.97460874,1.02083724, 1.00569659, 0.99931007, 0.97253711, 1.02816501, 0.9582612 , 0.99847442, 0.9663244 , 1.00026573, 0.97930598]\n",
    "up_trig = [1.04406395, 1.0161899 , 1.00818656, 1.01453322, 1.0504374,1.05290024, 1.01810422, 1.0107254 , 0.98913642, 1.06335367,0.99717576, 1.0172449 , 0.98301419, 1.02056413, 1.01756531]\n",
    "down_trig = [0.94615435, 1.00361001, 0.99175464, 0.99613031, 0.9455259, 1.00181298, 0.99597402, 0.98982106, 0.95861722, 1.00558644, 0.92292573, 0.98087248, 0.9504349 , 0.9812107 , 0.94474428]\n",
    "\n",
    "#2017\n",
    "nom_trig2017 = [1.01467505, 0.99558953, 0.99596328, 0.97266757, 1.01680672,0.91771569, 0.97330338, 0.9628086 , 0.94945886, 0.93074193,0.88346762, 0.93986709, 0.95049357, 0.96395947, 0.96216591 ]\n",
    "up_trig2017 = [1.08202419, 1.01316206, 1.00933387, 0.99761035, 1.09885624, 0.98177762, 0.99283257, 0.97860141, 0.96964921, 0.99310961, 0.93970839, 0.96592046, 0.97095216, 0.98912634, 1.01346021]\n",
    "down_trig2017 = [1.00919919, 0.9891299 , 0.98928763, 0.95716839, 1.01091358, 0.86905073, 0.95735603, 0.94920227, 0.93221049, 0.88617271,0.83084485, 0.91516138, 0.93099722, 0.94018822, 0.91551657 ]\n",
    "\n",
    "#2016\n",
    "nom_trig2016 = [1.00984252, 0.98759196, 0.99880955, 0.9905723 , 1.00215983,0.98220745, 1.01275276, 0.98584499, 1.00147192, 1.02677684,0.91866763, 1.00740741, 1.02089672, 1.04459947, 0.96555385 ]\n",
    "up_trig2016 = [1.08470782, 1.01762475, 1.01440987, 1.01465713, 1.09484157,1.03099084, 1.02538254, 1.00007443, 1.01757504, 1.06379468,0.98139906, 1.03550959, 1.04627989, 1.07175043, 1.02924617 ]\n",
    "down_trig2016 = [1.00555572, 0.97653751, 0.9930635 , 0.98174029, 1.00036919, 0.95711356, 1.00545487, 0.97463365, 0.99051333, 1.0122556,0.85933502, 0.98129079, 0.99705125, 1.01968035, 0.90658386 ]\n",
    "\n",
    "def applyTriggerSF_2018(lep_pt,lep_eta):\n",
    "    if lep_pt < 2000 and lep_pt > 200 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return nom_trig[0]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return nom_trig[1]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return nom_trig[2]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return nom_trig[3]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return nom_trig[4]\n",
    "    if lep_pt < 200 and lep_pt > 120 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return nom_trig[5]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return nom_trig[6]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return nom_trig[7]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return nom_trig[8]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return nom_trig[9]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return nom_trig[10]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return nom_trig[11]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return nom_trig[12]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return nom_trig[13]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return nom_trig[14]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def applyTriggerSF_2017(lep_pt,lep_eta):\n",
    "    if lep_pt < 2000 and lep_pt > 200 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return nom_trig2017[0]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return nom_trig2017[1]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return nom_trig2017[2]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return nom_trig2017[3]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return nom_trig2017[4]\n",
    "    if lep_pt < 200 and lep_pt > 120 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return nom_trig2017[5]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return nom_trig2017[6]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return nom_trig2017[7]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return nom_trig2017[8]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return nom_trig2017[9]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return nom_trig2017[10]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return nom_trig2017[11]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return nom_trig2017[12]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return nom_trig2017[13]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return nom_trig2017[14]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def applyTriggerSF_2016(lep_pt,lep_eta):\n",
    "    if lep_pt < 2000 and lep_pt > 200 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return nom_trig2016[0]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return nom_trig2016[1]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return nom_trig2016[2]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return nom_trig2016[3]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return nom_trig2016[4]\n",
    "    if lep_pt < 200 and lep_pt > 120 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return nom_trig2016[5]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return nom_trig2016[6]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return nom_trig2016[7]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return nom_trig2016[8]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return nom_trig2016[9]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return nom_trig2016[10]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return nom_trig2016[11]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return nom_trig2016[12]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return nom_trig2016[13]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return nom_trig2016[14]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "\n",
    "def applyTriggerSF_up_2018(lep_pt,lep_eta):\n",
    "    if lep_pt < 2000 and lep_pt > 200 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return up_trig[0]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return up_trig[1]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return up_trig[2]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return up_trig[3]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return up_trig[4]\n",
    "    if lep_pt < 200 and lep_pt > 120 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return up_trig[5]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return up_trig[6]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return up_trig[7]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return up_trig[8]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return up_trig[9]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return up_trig[10]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return up_trig[11]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return up_trig[12]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return up_trig[13]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return up_trig[14]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def applyTriggerSF_up_2017(lep_pt,lep_eta):\n",
    "    if lep_pt < 2000 and lep_pt > 200 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return up_trig2017[0]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return up_trig2017[1]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return up_trig2017[2]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return up_trig2017[3]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return up_trig2017[4]\n",
    "    if lep_pt < 200 and lep_pt > 120 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return up_trig2017[5]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return up_trig2017[6]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return up_trig2017[7]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return up_trig2017[8]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return up_trig2017[9]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return up_trig2017[10]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return up_trig2017[11]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return up_trig2017[12]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return up_trig2017[13]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return up_trig2017[14]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def applyTriggerSF_up_2016(lep_pt,lep_eta):\n",
    "    if lep_pt < 2000 and lep_pt > 200 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return up_trig2016[0]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return up_trig2016[1]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return up_trig2016[2]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return up_trig2016[3]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return up_trig2016[4]\n",
    "    if lep_pt < 200 and lep_pt > 120 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return up_trig2016[5]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return up_trig2016[6]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return up_trig2016[7]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return up_trig2016[8]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return up_trig2016[9]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return up_trig2016[10]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return up_trig2016[11]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return up_trig2016[12]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return up_trig2016[13]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return up_trig2016[14]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def applyTriggerSF_down_2018(lep_pt,lep_eta):\n",
    "    if lep_pt < 2000 and lep_pt > 200 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return down_trig[0]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return down_trig[1]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return down_trig[2]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return down_trig[3]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return down_trig[4]\n",
    "    if lep_pt < 200 and lep_pt > 120 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return down_trig[5]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return down_trig[6]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return down_trig[7]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return down_trig[8]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return down_trig[9]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return down_trig[10]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return down_trig[11]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return down_trig[12]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return down_trig[13]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return down_trig[14]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def applyTriggerSF_down_2017(lep_pt,lep_eta):\n",
    "    if lep_pt < 2000 and lep_pt > 200 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return down_trig2017[0]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return down_trig2017[1]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return down_trig2017[2]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return down_trig2017[3]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return down_trig2017[4]\n",
    "    if lep_pt < 200 and lep_pt > 120 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return down_trig2017[5]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return down_trig2017[6]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return down_trig2017[7]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return down_trig2017[8]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return down_trig2017[9]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return down_trig2017[10]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return down_trig2017[11]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return down_trig2017[12]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return down_trig2017[13]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return down_trig2017[14]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def applyTriggerSF_down_2016(lep_pt,lep_eta):\n",
    "    if lep_pt < 2000 and lep_pt > 200 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return down_trig2016[0]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return down_trig2016[1]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return down_trig2016[2]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return down_trig2016[3]\n",
    "    elif lep_pt < 2000 and lep_pt > 200 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return down_trig2016[4]\n",
    "    if lep_pt < 200 and lep_pt > 120 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return down_trig2016[5]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return down_trig2016[6]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return down_trig2016[7]\n",
    "    elif lep_pt < 200 and lep_pt > 120 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return down_trig2016[8]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return down_trig2016[9]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -1.5 and lep_eta > -2.5:\n",
    "        return down_trig2016[10]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < -0.5 and lep_eta > -1.5:\n",
    "        return down_trig2016[11]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 0.5 and lep_eta > -0.5:\n",
    "        return down_trig2016[12]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 1.5 and lep_eta > 0.5:\n",
    "        return down_trig2016[13]\n",
    "    elif lep_pt < 120 and lep_pt > 30 and lep_eta < 2.5 and lep_eta > 1.5:\n",
    "        return down_trig2016[14]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_templates(years, channels, samples, samples_dir, regions_sel, model_path, add_fake=False):\n",
    "    \"\"\"\n",
    "    Postprocesses the parquets by applying preselections, and fills templates for different regions.\n",
    "\n",
    "    Args\n",
    "        years [list]: years to postprocess (e.g. [\"2016APV\", \"2016\"])\n",
    "        ch [list]: channels to postprocess (e.g. [\"ele\", \"mu\"])\n",
    "        samples [list]: samples to postprocess (e.g. [\"ggF\", \"TTbar\", \"Data\"])\n",
    "        samples_dir [dict]: points to the path of the parquets for each region\n",
    "        regions_sel [dict]: key is the name of the region; value is the selection (e.g. `{\"pass\": (THWW>0.90)}`)\n",
    "        model_path [str]: path to the ParT finetuned model.onnx\n",
    "        add_fake [Bool]: if True will include Fake as an additional sample in the output hists\n",
    "\n",
    "    Returns\n",
    "        a dict() object hists[region] that contains histograms with 4 axes (Sample, Systematic, Region, mass_observable)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # add extra selections to preselection\n",
    "    presel = { \"mu\": { \"fj_mass\": \"fj_mass < 180\",}, \"ele\": {\"fj_mass\": \"fj_mass <180\",}, }\n",
    "\n",
    "    mass_binning = [40,70,108,180]\n",
    "     \n",
    "    hists = hist2.Hist(\n",
    "        hist2.axis.StrCategory([], name=\"Sample\", growth=True), hist2.axis.StrCategory([], name=\"Systematic\", growth=True), hist2.axis.StrCategory([], name=\"Region\", growth=True),\n",
    "        hist2.axis.Variable(\n",
    "            #list(range(55, 255, mass_binning)),\n",
    "            mass_binning, name=\"mass_observable\", label=r\"V reconstructed mass [GeV]\", overflow=True,\n",
    "        ), storage=hist2.storage.Weight(),\n",
    "    )\n",
    "\n",
    "    SYST_DICT = get_systematic_dict(years)\n",
    "\n",
    "    for year in years:  # e.g. 2018, 2017, 2016APV, 2016\n",
    "\n",
    "        \n",
    "        for ch in channels:  # e.g. mu, ele\n",
    "            logging.info(f\"Processing year {year} and {ch} channel\")\n",
    "\n",
    "            with open(\"../../fileset/luminosity.json\") as f:\n",
    "                luminosity = json.load(f)[ch][year]\n",
    "\n",
    "            for sample in os.listdir(samples_dir[year]):\n",
    "\n",
    "                sample_to_use = get_common_sample_name(sample)\n",
    "\n",
    "                if sample_to_use not in samples:\n",
    "                    continue\n",
    "\n",
    "                is_data = True if sample_to_use == \"Data\" else False\n",
    "\n",
    "                logging.info(f\"Finding {sample} samples and should combine them under {sample_to_use}\")\n",
    "\n",
    "                out_files = f\"{samples_dir[year]}/{sample}/outfiles/\"\n",
    "                parquet_files = glob.glob(f\"{out_files}/*_{ch}.parquet\")\n",
    "                pkl_files = glob.glob(f\"{out_files}/*.pkl\")\n",
    "\n",
    "                if not parquet_files:\n",
    "                    logging.info(f\"No parquet file for {sample}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    data = pd.read_parquet(parquet_files)\n",
    "                except pyarrow.lib.ArrowInvalid:  # empty parquet because no event passed selection\n",
    "                    continue\n",
    "\n",
    "                if len(data) == 0:\n",
    "                    continue\n",
    "\n",
    "                data[\"THWW\"] = get_finetuned_score(data, model_path)\n",
    "                data = data[data.columns.drop(list(data.filter(regex=\"hidNeuron\")))]\n",
    "\n",
    "                for selection in presel[ch]:\n",
    "                    logging.info(f\"Applying {selection} selection on {len(data)} events\")\n",
    "                    data = data.query(presel[ch][selection])\n",
    "\n",
    "#********************************************************************************************************\n",
    "                    \n",
    "                    if not is_data:\n",
    "\n",
    "                        data['met_pt_UES_up'] = data['ues_up']\n",
    "                        data['met_pt_UES_down'] = data['ues_down'] #to do: reame in processor to elim. this step\n",
    "\n",
    "                        data['temp_JESdown'] = data['met_pt_JES_down']\n",
    "                        data['temp_JESup'] = data['met_pt_JES_up']\n",
    "                        data[['met_pt_JES_down', 'met_pt_JES_up']]= data[['temp_JESup', 'temp_JESdown']]\n",
    "                        data['temp_JERdown'] = data['met_pt_JER_down']\n",
    "                        data['temp_JERup'] = data['met_pt_JER_up']\n",
    "                        data[['met_pt_JER_down', 'met_pt_JER_up']]= data[['temp_JERup', 'temp_JERdown']]\n",
    "                        data['temp_JES_FlavorQCD_down'] = data['met_pt_JES_FlavorQCD_down']\n",
    "                        data['temp_JES_FlavorQCD_up'] = data['met_pt_JES_FlavorQCD_up']\n",
    "                        data[['met_pt_JES_FlavorQCD_down', 'met_pt_JES_FlavorQCD_up']]= data[['temp_JES_FlavorQCD_up', 'temp_JES_FlavorQCD_down']]\n",
    "                        data['temp_JESRelativeBal_down'] = data['met_pt_JES_RelativeBal_down']\n",
    "                        data['temp_JESRelativeBal_up'] = data['met_pt_JES_RelativeBal_up']\n",
    "                        data[['met_pt_JES_RelativeBal_down', 'met_pt_JES_RelativeBal_up']]= data[['temp_JESRelativeBal_up', 'temp_JESRelativeBal_down']]\n",
    "                        data['temp_JES_HF_down'] = data['met_pt_JES_HF_down']\n",
    "                        data['temp_JES_HF_up'] = data['met_pt_JES_HF_up']\n",
    "                        data[['met_pt_JES_HF_down', 'met_pt_JES_HF_up']]= data[['temp_JES_HF_up', 'temp_JES_HF_down']]\n",
    "                        data['temp_JES_BBEC1_down'] = data['met_pt_JES_BBEC1_down']\n",
    "                        data['temp_JES_BBEC1_up'] = data['met_pt_JES_BBEC1_up']\n",
    "                        data[['met_pt_JES_BBEC1_down', 'met_pt_JES_BBEC1_up']]= data[['temp_JES_BBEC1_up', 'temp_JES_BBEC1_down']]\n",
    "                        data['temp_JES_EC2_down'] = data['met_pt_JES_EC2_down']\n",
    "                        data['temp_JES_EC2_up'] = data['met_pt_JES_EC2_up']\n",
    "                        data[['met_pt_JES_EC2_down', 'met_pt_JES_EC2_up']]= data[['temp_JES_EC2_up', 'temp_JES_EC2_down']]\n",
    "                        data['temp_JES_Absolute_down'] = data['met_pt_JES_Absolute_down']\n",
    "                        data['temp_JES_Absolute_up'] = data['met_pt_JES_Absolute_up']\n",
    "                        data[['met_pt_JES_Absolute_down', 'met_pt_JES_Absolute_up']]= data[['temp_JES_Absolute_up', 'temp_JES_Absolute_down']]\n",
    "                        data['temp_JES_Total_down'] = data['met_pt_JES_Total_down']\n",
    "                        data['temp_JES_Total_up'] = data['met_pt_JES_Total_up']\n",
    "                        data[['met_pt_JES_Total_down', 'met_pt_JES_Total_up']]= data[['temp_JES_Total_up', 'temp_JES_Total_down']]\n",
    "\n",
    "                        if year == '2018':\n",
    "                            data['temp_JES_BBEC1_2018_down'] = data['met_pt_JES_BBEC1_2018_down']\n",
    "                            data['temp_JES_BBEC1_2018_up'] = data['met_pt_JES_BBEC1_2018_up']\n",
    "                            data[['met_pt_JES_BBEC1_2018_down', 'met_pt_JES_BBEC1_2018_up']]= data[['temp_JES_BBEC1_2018_up', 'temp_JES_BBEC1_2018_down']]\n",
    "                            data['temp_JES_RelativeSample_2018_down'] = data['met_pt_JES_RelativeSample_2018_down']\n",
    "                            data['temp_JES_RelativeSample_2018_up'] = data['met_pt_JES_RelativeSample_2018_up']\n",
    "                            data[['met_pt_JES_RelativeSample_2018_down', 'met_pt_JES_RelativeSample_2018_up']]= data[['temp_JES_RelativeSample_2018_up', 'temp_JES_RelativeSample_2018_down']]\n",
    "                            data['temp_JES_EC2_2018_down'] = data['met_pt_JES_EC2_2018_down']\n",
    "                            data['temp_JES_EC2_2018_up'] = data['met_pt_JES_EC2_2018_up']\n",
    "                            data[['met_pt_JES_EC2_2018_down', 'met_pt_JES_EC2_2018_up']]= data[['temp_JES_EC2_2018_up', 'temp_JES_EC2_2018_down']]\n",
    "                            data['temp_JES_HF_2018_down'] = data['met_pt_JES_HF_2018_down']\n",
    "                            data['temp_JES_HF_2018_up'] = data['met_pt_JES_HF_2018_up']\n",
    "                            data[['met_pt_JES_HF_2018_down', 'met_pt_JES_HF_2018_up']]= data[['temp_JES_HF_2018_up', 'temp_JES_HF_2018_down']]\n",
    "                            data['temp_JES_Absolute_2018_down'] = data['met_pt_JES_Absolute_2018_down']\n",
    "                            data['temp_JES_Absolute_2018_up'] = data['met_pt_JES_Absolute_2018_up']\n",
    "                            data[['met_pt_JES_Absolute_2018_down', 'met_pt_JES_Absolute_2018_up']]= data[['temp_JES_Absolute_2018_up', 'temp_JES_Absolute_2018_down']]\n",
    "\n",
    "                        elif year == '2017':\n",
    "                            data['temp_JES_BBEC1_2017_down'] = data['met_pt_JES_BBEC1_2017_down']\n",
    "                            data['temp_JES_BBEC1_2017_up'] = data['met_pt_JES_BBEC1_2017_up']\n",
    "                            data[['met_pt_JES_BBEC1_2017_down', 'met_pt_JES_BBEC1_2017_up']]= data[['temp_JES_BBEC1_2017_up', 'temp_JES_BBEC1_2017_down']]\n",
    "                            data['temp_JES_RelativeSample_2017_down'] = data['met_pt_JES_RelativeSample_2017_down']\n",
    "                            data['temp_JES_RelativeSample_2017_up'] = data['met_pt_JES_RelativeSample_2017_up']\n",
    "                            data[['met_pt_JES_RelativeSample_2017_down', 'met_pt_JES_RelativeSample_2017_up']]= data[['temp_JES_RelativeSample_2017_up', 'temp_JES_RelativeSample_2017_down']]\n",
    "                            data['temp_JES_EC2_2017_down'] = data['met_pt_JES_EC2_2017_down']\n",
    "                            data['temp_JES_EC2_2017_up'] = data['met_pt_JES_EC2_2017_up']\n",
    "                            data[['met_pt_JES_EC2_2017_down', 'met_pt_JES_EC2_2017_up']]= data[['temp_JES_EC2_2017_up', 'temp_JES_EC2_2017_down']]\n",
    "                            data['temp_JES_HF_2017_down'] = data['met_pt_JES_HF_2017_down']\n",
    "                            data['temp_JES_HF_2017_up'] = data['met_pt_JES_HF_2017_up']\n",
    "                            data[['met_pt_JES_HF_2017_down', 'met_pt_JES_HF_2017_up']]= data[['temp_JES_HF_2017_up', 'temp_JES_HF_2017_down']]\n",
    "                            data['temp_JES_Absolute_2017_down'] = data['met_pt_JES_Absolute_2017_down']\n",
    "                            data['temp_JES_Absolute_2017_up'] = data['met_pt_JES_Absolute_2017_up']\n",
    "                            data[['met_pt_JES_Absolute_2017_down', 'met_pt_JES_Absolute_2017_up']]= data[['temp_JES_Absolute_2017_up', 'temp_JES_Absolute_2017_down']]\n",
    "\n",
    "                        elif year == '2016' or year == '2016APV':\n",
    "                            data['temp_JES_BBEC1_2016_down'] = data['met_pt_JES_BBEC1_2016_down']\n",
    "                            data['temp_JES_BBEC1_2016_up'] = data['met_pt_JES_BBEC1_2016_up']\n",
    "                            data[['met_pt_JES_BBEC1_2016_down', 'met_pt_JES_BBEC1_2016_up']]= data[['temp_JES_BBEC1_2016_up', 'temp_JES_BBEC1_2016_down']]\n",
    "                            data['temp_JES_RelativeSample_2016_down'] = data['met_pt_JES_RelativeSample_2016_down']\n",
    "                            data['temp_JES_RelativeSample_2016_up'] = data['met_pt_JES_RelativeSample_2016_up']\n",
    "                            data[['met_pt_JES_RelativeSample_2016_down', 'met_pt_JES_RelativeSample_2016_up']]= data[['temp_JES_RelativeSample_2016_up', 'temp_JES_RelativeSample_2016_down']]\n",
    "                            data['temp_JES_EC2_2016_down'] = data['met_pt_JES_EC2_2016_down']\n",
    "                            data['temp_JES_EC2_2016_up'] = data['met_pt_JES_EC2_2016_up']\n",
    "                            data[['met_pt_JES_EC2_2016_down', 'met_pt_JES_EC2_2016_up']]= data[['temp_JES_EC2_2016_up', 'temp_JES_EC2_2016_down']]\n",
    "                            data['temp_JES_HF_2016_down'] = data['met_pt_JES_HF_2016_down']\n",
    "                            data['temp_JES_HF_2016_up'] = data['met_pt_JES_HF_2016_up']\n",
    "                            data[['met_pt_JES_HF_2016_down', 'met_pt_JES_HF_2016_up']]= data[['temp_JES_HF_2016_up', 'temp_JES_HF_2016_down']]\n",
    "                            data['temp_JES_Absolute_2016_down'] = data['met_pt_JES_Absolute_2016_down']\n",
    "                            data['temp_JES_Absolute_2016_up'] = data['met_pt_JES_Absolute_2016_up']\n",
    "                            data[['met_pt_JES_Absolute_2016_down', 'met_pt_JES_Absolute_2016_up']]= data[['temp_JES_Absolute_2016_up', 'temp_JES_Absolute_2016_down']]\n",
    "\n",
    "#********************************************************************************************************\n",
    "                # get the xsecweight\n",
    "                xsecweight, sumgenweights, sumpdfweights, sumscaleweights = get_xsecweight( pkl_files, year, sample, sample_to_use, is_data, luminosity)\n",
    "\n",
    "                for region, region_sel in regions_sel.items():  # e.g. pass, fail, top control region, etc.\n",
    "                #need to apply the V calibration only when making a cut on V tagger; currently the TTbar CR has no cut on tagger, so don't apply it\n",
    "\n",
    "#**************************************************************************************\n",
    "                    df = data.copy()\n",
    "                    logging.info(f\"Applying {region} selection on {len(df)} events\")\n",
    "                    df = df.query(region_sel)\n",
    "                    logging.info(f\"Will fill the histograms with the remaining {len(df)} events\")\n",
    "\n",
    "                    # ------------------- Nominal -------------------\n",
    "                    if is_data:\n",
    "                        nominal = np.ones_like(df[\"fj_pt\"])  # for data (nominal is 1)\n",
    "                    else:\n",
    "                        nominal = df[f\"weight_{ch}\"] * xsecweight * df[\"weight_btag\"] \n",
    "\n",
    "\n",
    "                #************\n",
    "                        #these three lines need to be uncommented for trigger \n",
    "                        if ch == 'ele':\n",
    "                            if year == '2018':\n",
    "                                df['temp'] = df.apply(lambda row:applyTriggerSF_2018(row['lep_pt'],row['lep_eta']),axis=1)\n",
    "                                nominal *=  df['temp']\n",
    "                                df.drop(columns=['temp'],axis=1)\n",
    "                            elif year == '2017':\n",
    "                                df['temp'] = df.apply(lambda row:applyTriggerSF_2017(row['lep_pt'],row['lep_eta']),axis=1)\n",
    "                                nominal *=  df['temp']\n",
    "                                df.drop(columns=['temp'],axis=1)\n",
    "                            else:\n",
    "                                df['temp'] = df.apply(lambda row:applyTriggerSF_2016(row['lep_pt'],row['lep_eta']),axis=1)\n",
    "                                nominal *=  df['temp']\n",
    "                                df.drop(columns=['temp'],axis=1)        \n",
    "                #************\n",
    "                        if sample_to_use == \"TTbar\":\n",
    "                            nominal *= df[\"top_reweighting\"]\n",
    "                    ###################################\n",
    "                        if sample_to_use == \"EWKvjets\":\n",
    "                            threshold = 20\n",
    "                            df = df[nominal < threshold]\n",
    "                            nominal = nominal[nominal < threshold]\n",
    "                    ###################################\n",
    "\n",
    "                    hists.fill( Sample=sample_to_use, Systematic=\"pass_nominal\", Region=region, mass_observable=df[\"fj_mass\"], weight=nominal,)\n",
    "\n",
    "#*****************************histo for up and down trigger scale factor for electron only\n",
    "                    for syst, (yrs, smpls, var) in SYST_DICT[\"TRIGGER_systs\"].items(): #this dictionary only applies it to electron\n",
    "                        if year == '2018':\n",
    "                            if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                                    df['weight_up'] = df.apply(lambda row:applyTriggerSF_up_2018(row['lep_pt'],row['lep_eta']),axis=1)\n",
    "                                    df[\"weight_down\"] = df.apply(lambda row:applyTriggerSF_down_2018(row['lep_pt'],row['lep_eta']),axis=1)\n",
    "                                    shape_up=nominal*df['weight_up']\n",
    "                                    shape_down=nominal*df['weight_down']\n",
    "                                    df.drop(columns=['weight_up'],axis=1)\n",
    "                                    df.drop(columns=['weight_down'],axis=1)\n",
    "                            else:\n",
    "                                    shape_up = nominal\n",
    "                                    shape_down = nominal\n",
    "\n",
    "                        elif year == '2017':\n",
    "                            if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                                    df['weight_up'] = df.apply(lambda row:applyTriggerSF_up_2017(row['lep_pt'],row['lep_eta']),axis=1)\n",
    "                                    df[\"weight_down\"] = df.apply(lambda row:applyTriggerSF_down_2017(row['lep_pt'],row['lep_eta']),axis=1)\n",
    "                                    shape_up=nominal*df['weight_up']\n",
    "                                    shape_down=nominal*df['weight_down']\n",
    "                                    df.drop(columns=['weight_up'],axis=1)\n",
    "                                    df.drop(columns=['weight_down'],axis=1)\n",
    "                            else:\n",
    "                                    shape_up = nominal\n",
    "                                    shape_down = nominal\n",
    "\n",
    "                        else:\n",
    "                            if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                                    df['weight_up'] = df.apply(lambda row:applyTriggerSF_up_2016(row['lep_pt'],row['lep_eta']),axis=1)\n",
    "                                    df[\"weight_down\"] = df.apply(lambda row:applyTriggerSF_down_2016(row['lep_pt'],row['lep_eta']),axis=1)\n",
    "                                    shape_up=nominal*df['weight_up']\n",
    "                                    shape_down=nominal*df['weight_down']\n",
    "                                    df.drop(columns=['weight_up'],axis=1)\n",
    "                                    df.drop(columns=['weight_down'],axis=1)\n",
    "                            else:\n",
    "                                    shape_up = nominal\n",
    "                                    shape_down = nominal\n",
    "                        \n",
    "                        hists.fill( Sample=sample_to_use, Systematic=f\"{syst}_up\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_up )\n",
    "                        hists.fill( Sample=sample_to_use, Systematic=f\"{syst}_down\", Region=region, mass_observable=df[\"fj_mass\"],weight=shape_down )\n",
    "    \n",
    "#*****************************************************************************************\n",
    "                    # ------------------- PDF acceptance -------------------\n",
    "                    \"\"\"\n",
    "                    For the PDF acceptance uncertainty:\n",
    "                    - store 103 variations. 0-100 PDF values, The last two values: alpha_s variations.\n",
    "                    - you just sum the yield difference from the nominal in quadrature to get the total uncertainty.\n",
    "                    e.g. https://github.com/LPC-HH/HHLooper/blob/master/python/prepare_card_SR_final.py#L258\n",
    "                    and https://github.com/LPC-HH/HHLooper/blob/master/app/HHLooper.cc#L1488\n",
    "                    \"\"\"\n",
    "                    # if sample_to_use in sigs:\n",
    "                    if (sample_to_use in sigs + [\"WJetsLNu\", \"TTbar\"]) and (sample != \"ST_s-channel_4f_hadronicDecays\"):\n",
    "                        pdfweights = []\n",
    "                        for weight_i in sumpdfweights:\n",
    "                            # noqa: get the normalization factor per variation i (ratio of sumpdfweights_i/sumgenweights)\n",
    "                            R_i = sumpdfweights[weight_i] / sumgenweights\n",
    "                            pdfweight = df[f\"weight_pdf{weight_i}\"].values * nominal / R_i\n",
    "                            pdfweights.append(pdfweight)\n",
    "                        pdfweights = np.swapaxes(np.array(pdfweights), 0, 1)  # so that the shape is (# events, variation)\n",
    "                        abs_unc = np.linalg.norm((pdfweights - nominal.values.reshape(-1, 1)), axis=1)\n",
    "                        # cap at 100% uncertainty\n",
    "                        rel_unc = np.clip(abs_unc / nominal, 0, 1)\n",
    "                        shape_up = nominal * (1 + rel_unc)\n",
    "                        shape_down = nominal * (1 - rel_unc)\n",
    "                    else:\n",
    "                        shape_up = nominal\n",
    "                        shape_down = nominal\n",
    "\n",
    "                    #hists.fill(Sample=sample_to_use, Systematic=\"pass_weight_pdf_acceptance_up\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_up, )\n",
    "                    #hists.fill( Sample=sample_to_use, Systematic=\"pass_weight_pdf_acceptance_down\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_down,)\n",
    "\n",
    "                    hists.fill(Sample=sample_to_use, Systematic=f\"pass_weight_pdf_acceptance_{sample_to_use}_up\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_up, )\n",
    "                    hists.fill( Sample=sample_to_use, Systematic=f\"pass_weight_pdf_acceptance_{sample_to_use}_down\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_down,)\n",
    "\n",
    "                    \n",
    "                    # ------------------- QCD scale -------------------\n",
    "                    \"\"\"\n",
    "                    For the QCD acceptance uncertainty:\n",
    "                    - we save the individual weights [0, 1, 3, 5, 7, 8]\n",
    "                    - postprocessing: we obtain sum_sumlheweight\n",
    "                    - postprocessing: we obtain LHEScaleSumw: sum_sumlheweight[i] / sum_sumgenweight\n",
    "                    - postprocessing:\n",
    "                    obtain histograms for 0, 1, 3, 5, 7, 8 and 4: h0, h1, ... respectively\n",
    "                    weighted by scale_0, scale_1, etc\n",
    "                    and normalize them by  (xsec * luminosity) / LHEScaleSumw[i]\n",
    "                    - then, take max/min of h0, h1, h3, h5, h7, h8 w.r.t h4: h_up and h_dn\n",
    "                    - the uncertainty is the nominal histogram * h_up / h4\n",
    "                    \"\"\"\n",
    "                    if (sample_to_use in sigs + [\"WJetsLNu\", \"TTbar\", \"SingleTop\"]) and (sample != \"ST_s-channel_4f_hadronicDecays\" ):\n",
    "                        R_4 = sumscaleweights[4] / sumgenweights\n",
    "                        scaleweight_4 = df[\"weight_scale4\"].values * nominal / R_4\n",
    "\n",
    "                        scaleweights = []\n",
    "                        for weight_i in sumscaleweights:\n",
    "                            if weight_i == 4:\n",
    "                                continue\n",
    "                            # get the normalization factor per variation i (ratio of sumscaleweights_i/sumgenweights)\n",
    "                            R_i = sumscaleweights[weight_i] / sumgenweights\n",
    "                            scaleweight_i = df[f\"weight_scale{weight_i}\"].values * nominal / R_i\n",
    "                            scaleweights.append(scaleweight_i)\n",
    "\n",
    "                        scaleweights = np.array(scaleweights)\n",
    "                        scaleweights = np.swapaxes(np.array(scaleweights), 0, 1  )  # so that the shape is (# events, variation)\n",
    "                        # TODO: debug\n",
    "                        shape_up = nominal * np.max(scaleweights, axis=1) / scaleweight_4\n",
    "                        shape_down = nominal * np.min(scaleweights, axis=1) / scaleweight_4\n",
    "                    else:\n",
    "                        shape_up = nominal\n",
    "                        shape_down = nominal\n",
    "\n",
    "                    hists.fill(Sample=sample_to_use, Systematic=f\"pass_weight_qcd_scale_{sample_to_use}_up\", Region=region, mass_observable=df[\"fj_mass\"],  weight=shape_up,)\n",
    "                    hists.fill( Sample=sample_to_use, Systematic=f\"pass_weight_qcd_scale_{sample_to_use}_down\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_down, )\n",
    "\n",
    "                    # ------------------- Top pt reweighting systematic  -------------------\n",
    "\n",
    "                    if sample_to_use == \"TTbar\":\n",
    "                        # first remove the reweighting effect\n",
    "                        nominal_noreweighting = nominal / df[\"top_reweighting\"]\n",
    "\n",
    "                        shape_up = nominal_noreweighting * (df[\"top_reweighting\"] ** 2)  # \"up\" is twice the correction\n",
    "                        shape_down = nominal_noreweighting  # \"down\" is no correction\n",
    "                    else:\n",
    "                        shape_up = nominal\n",
    "                        shape_down = nominal\n",
    "\n",
    "                    hists.fill( Sample=sample_to_use, Systematic=\"pass_top_reweighting_up\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_up,)\n",
    "                    hists.fill( Sample=sample_to_use, Systematic=\"pass_top_reweighting_down\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_down,)\n",
    "\n",
    "                    # ------------------- Common systematics  -------------------\n",
    "\n",
    "#nominal has event weight, but event weight already has pileup weight in it since it is a product of various event weights, so i guess that is why farouk only has xsec weight.\n",
    "                        #nominal = df[f\"weight_{ch}\"] * xsecweight * df[\"weight_btag\"]\n",
    "                    for syst, (yrs, smpls, var) in SYST_DICT[\"common\"].items():\n",
    "                        #print('syst', syst)\n",
    "                        if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                            shape_up = df[var[ch] + \"Up\"] * xsecweight * df[\"weight_btag\"] \n",
    "                            shape_down = df[var[ch] + \"Down\"] * xsecweight * df[\"weight_btag\"] \n",
    "                            if sample_to_use == \"TTbar\":\n",
    "                                shape_up *= df[\"top_reweighting\"]\n",
    "                                shape_down *= df[\"top_reweighting\"]\n",
    "                        else:\n",
    "                            shape_up = nominal\n",
    "                            shape_down = nominal\n",
    "                        hists.fill( Sample=sample_to_use, Systematic=f\"{syst}_up\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_up, )\n",
    "                        hists.fill( Sample=sample_to_use, Systematic=f\"{syst}_down\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_down, )\n",
    "\n",
    "                    for syst, (yrs, smpls, var) in SYST_DICT[\"psrad\"].items():\n",
    "                        #print('syst', syst)\n",
    "                        if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                            shape_up = df[var[ch] + \"Up\"] * xsecweight * df[\"weight_btag\"] \n",
    "                            shape_down = df[var[ch] + \"Down\"] * xsecweight * df[\"weight_btag\"] \n",
    "                            if sample_to_use == \"TTbar\":\n",
    "                                shape_up *= df[\"top_reweighting\"]\n",
    "                                shape_down *= df[\"top_reweighting\"]\n",
    "                        else:\n",
    "                            shape_up = nominal\n",
    "                            shape_down = nominal\n",
    "                        hists.fill( Sample=sample_to_use, Systematic=f\"{syst}_{sample_to_use}_up\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_up, )\n",
    "                        hists.fill( Sample=sample_to_use, Systematic=f\"{syst}_{sample_to_use}_down\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_down, )\n",
    "\n",
    "\n",
    "                    for syst, (yrs, smpls, var) in SYST_DICT[\"btag1\"].items():  #this works %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "                        if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                            shape_up = df[var[ch] + \"Up\"]  * xsecweight * df[f\"weight_{ch}\"] \n",
    "                            shape_down = df[var[ch] + \"Down\"]  * xsecweight * df[f\"weight_{ch}\"] \n",
    "                        else:                       \n",
    "                            shape_up = df['fj_mass']\n",
    "                            shape_down = df['fj_mass']\n",
    "                        if sample_to_use == \"TTbar\":\n",
    "                            shape_up *= df[\"top_reweighting\"]\n",
    "                            shape_down *= df[\"top_reweighting\"]\n",
    "\n",
    "                        hists.fill(Sample=sample_to_use, Systematic=f\"{syst}_up\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_up,)\n",
    "                        hists.fill(Sample=sample_to_use, Systematic=f\"{syst}_down\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_down,)\n",
    "\n",
    "                   #****************************************btag by year:\n",
    "                    for syst, (yrs, smpls, var) in SYST_DICT[\"btag2\"].items(): \n",
    "                        if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                            #print('btag2 syst', syst, sample_to_use,year,ch)\n",
    "                            #print('df[var[ch]', (df[var[ch]]))\n",
    "                            shape_up = df[var[ch] + \"Up\"]  * xsecweight * df[f\"weight_{ch}\"]  \n",
    "                            shape_down = df[var[ch] + \"Down\"] * xsecweight * df[f\"weight_{ch}\"]          \n",
    "                        else:                       \n",
    "                            shape_up = df['fj_mass']\n",
    "                            shape_down = df['fj_mass']\n",
    "                        if sample_to_use == \"TTbar\":\n",
    "                                shape_up *= df[\"top_reweighting\"]\n",
    "                                shape_down *= df[\"top_reweighting\"]\n",
    "                        hists.fill(Sample=sample_to_use, Systematic=f\"{syst}_up\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_up)\n",
    "                        hists.fill(Sample=sample_to_use, Systematic=f\"{syst}_down\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_down)\n",
    "                        #else:  #NOTE: don't apply top reweighting below b/c nominal already had it applied for ttbar samples\n",
    "                         #   shape_up =  nominal\n",
    "                          #  shape_down = nominal\n",
    "                           # hists.fill(Sample=sample_to_use, Systematic=f\"{syst}_up\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_up)\n",
    "                            #hists.fill(Sample=sample_to_use, Systematic=f\"{syst}_down\", Region=region, mass_observable=df[\"fj_mass\"], weight=shape_down)\n",
    "\n",
    "                   # ------------------- individual sources of JES -------------------\n",
    "                #HERE IS A NEW REGION SELECTION, and NEW definition of nominal **********************************\n",
    "                \"\"\"We apply the jet pt cut on the up/down variations. Must loop over systematics first.\"\"\"\n",
    "                for syst, (yrs, smpls, var) in SYST_DICT[\"JEC\"].items():\n",
    "                    for variation in [\"up\", \"down\"]:\n",
    "                        for region, region_sel in regions_sel.items():  # e.g. pass, fail, top control region, etc.\n",
    "                            if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                                region_sel = region_sel.replace(\"fj_pt\", \"fj_pt\" + var[ch] + f\"_{variation}\")\n",
    "                                region_sel = region_sel.replace(\"met_pt\", \"met_pt_\" + var[ch] + f\"_{variation}\")\n",
    "                                region_sel = region_sel.replace(\"numberBJets_Medium_OutsideFatJets\", \"numberBJets_\" + var[ch] + f\"_{variation}\")\n",
    "\n",
    "                            df = data.copy()\n",
    "                            df = df.query(region_sel)\n",
    "                            # ------------------- Nominal -------------------\n",
    "                            if is_data:\n",
    "                                nominal = np.ones_like(df[\"fj_pt\"])  # for data (nominal is 1)\n",
    "                            else:\n",
    "                                nominal = df[f\"weight_{ch}\"] * xsecweight * df[\"weight_btag\"] \n",
    "\n",
    "                            if sample_to_use == \"TTbar\":\n",
    "                                nominal *= df[\"top_reweighting\"]\n",
    "                            if sample_to_use == \"EWKvjets\":\n",
    "                                threshold = 20\n",
    "                                df = df[nominal < threshold]\n",
    "                                nominal = nominal[nominal < threshold]\n",
    "\n",
    "                            if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                                shape_variation = df[\"fj_mass\"] # + var[ch] + f\"_{variation}\"]\n",
    "                            else:\n",
    "                                shape_variation = df[\"fj_mass\"]\n",
    "\n",
    "                            hists.fill( Sample=sample_to_use, Systematic=f\"{syst}_{variation}\", Region=region, mass_observable=shape_variation, weight=nominal,)\n",
    "\n",
    "                for syst, (yrs, smpls, var) in SYST_DICT[\"UES_systs\"].items():\n",
    "                    #print('variation', variation)\n",
    "                    for variation in [\"up\", \"down\"]:\n",
    "                        for region, region_sel in regions_sel.items():  # e.g. pass, fail, top control region, etc.\n",
    "                            if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                                region_sel = region_sel.replace(\"met_pt\", \"met_pt_\" + var[ch] + f\"_{variation}\")\n",
    "                               # print('region_sel', region_sel)\n",
    "                            df = data.copy()\n",
    "                            df = df.query(region_sel)\n",
    "                            # ------------------- Nominal -------------------\n",
    "                            if is_data:\n",
    "                                nominal = np.ones_like(df[\"fj_pt\"])  # for data (nominal is 1)\n",
    "                            else:\n",
    "                                nominal = df[f\"weight_{ch}\"] * xsecweight * df[\"weight_btag\"]\n",
    "\n",
    "                            if sample_to_use == \"TTbar\":\n",
    "                                nominal *= df[\"top_reweighting\"]\n",
    "                            if sample_to_use == \"EWKvjets\":\n",
    "                                threshold = 20\n",
    "                                df = df[nominal < threshold]\n",
    "                                nominal = nominal[nominal < threshold]\n",
    "\n",
    "                            if (sample_to_use in smpls) and (year in yrs) and (ch in var):\n",
    "                                shape_variation = df[\"fj_mass\"]\n",
    "                            else:\n",
    "                                shape_variation = df[\"fj_mass\"]\n",
    "\n",
    "                            hists.fill( Sample=sample_to_use, Systematic=f\"{syst}_{variation}\", Region=region, mass_observable=shape_variation, weight=nominal,)\n",
    "\n",
    "    \n",
    "    return hists\n",
    "\n",
    "\n",
    "def fix_neg_yields(h):\n",
    "    \"\"\"\n",
    "    Will set the bin yields of a process to 0 if the nominal yield is negative, and will\n",
    "    set the yield to 0 for the full Systematic axis.\n",
    "    \"\"\"\n",
    "    for region in h.axes[\"Region\"]:\n",
    "        for sample in h.axes[\"Sample\"]:\n",
    "            neg_bins = np.where(h[{\"Sample\": sample, \"Systematic\": \"pass_nominal\", \"Region\": region}].values() < 0)[0]\n",
    "\n",
    "            if len(neg_bins) > 0:\n",
    "                print('got neg bins')\n",
    "                print(f\"{region}, {sample}, has {len(neg_bins)} bins with negative yield.. will set them to 0\")\n",
    "\n",
    "                sample_index = np.argmax(np.array(h.axes[\"Sample\"]) == sample)\n",
    "                region_index = np.argmax(np.array(h.axes[\"Region\"]) == region)\n",
    "\n",
    "                for neg_bin in neg_bins:\n",
    "                    h.view(flow=True)[sample_index, :, region_index, neg_bin + 1].value = 1e-3\n",
    "                    h.view(flow=True)[sample_index, :, region_index, neg_bin + 1].variance = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2676f130-3778-4ea2-b179-e9cf1f6423f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing year 2016 and mu channel\n",
      "INFO:root:Finding ZJetsToQQ_HT-200to400 samples and should combine them under ZQQ\n",
      "INFO:root:Finding ZJetsToQQ_HT-400to600 samples and should combine them under ZQQ\n",
      "INFO:root:Applying fj_mass selection on 61 events\n",
      "INFO:root:Applying SR1 selection on 61 events\n",
      "INFO:root:Will fill the histograms with the remaining 0 events\n",
      "INFO:root:Finding ZJetsToQQ_HT-600to800 samples and should combine them under ZQQ\n",
      "INFO:root:Applying fj_mass selection on 357 events\n",
      "INFO:root:Applying SR1 selection on 357 events\n",
      "INFO:root:Will fill the histograms with the remaining 1 events\n",
      "INFO:root:Finding ZJetsToQQ_HT-800toInf samples and should combine them under ZQQ\n",
      "INFO:root:Applying fj_mass selection on 718 events\n",
      "INFO:root:Applying SR1 selection on 659 events\n",
      "INFO:root:Will fill the histograms with the remaining 2 events\n",
      "INFO:root:Processing year 2016 and ele channel\n",
      "INFO:root:Finding ZJetsToQQ_HT-200to400 samples and should combine them under ZQQ\n",
      "INFO:root:Finding ZJetsToQQ_HT-400to600 samples and should combine them under ZQQ\n",
      "INFO:root:Applying fj_mass selection on 38 events\n",
      "INFO:root:Applying SR1 selection on 38 events\n",
      "INFO:root:Will fill the histograms with the remaining 0 events\n",
      "INFO:root:Finding ZJetsToQQ_HT-600to800 samples and should combine them under ZQQ\n",
      "INFO:root:Applying fj_mass selection on 198 events\n",
      "INFO:root:Applying SR1 selection on 198 events\n",
      "INFO:root:Will fill the histograms with the remaining 0 events\n",
      "INFO:root:Finding ZJetsToQQ_HT-800toInf samples and should combine them under ZQQ\n",
      "INFO:root:Applying fj_mass selection on 334 events\n",
      "INFO:root:Applying SR1 selection on 309 events\n",
      "INFO:root:Will fill the histograms with the remaining 0 events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hists Hist(\n",
      "  StrCategory(['ZQQ'], growth=True, name='Sample'),\n",
      "  StrCategory(['pass_nominal', 'pass_weight_trigger_up', 'pass_weight_trigger_down', 'pass_weight_pdf_acceptance_ZQQ_up', 'pass_weight_pdf_acceptance_ZQQ_down', 'pass_weight_qcd_scale_ZQQ_up', 'pass_weight_qcd_scale_ZQQ_down', 'pass_top_reweighting_up', 'pass_top_reweighting_down', 'pass_weight_pileup_id_up', 'pass_weight_pileup_id_down', 'pass_weight_d1K_NLO_up', 'pass_weight_d1K_NLO_down', 'pass_weight_d2K_NLO_up', 'pass_weight_d2K_NLO_down', 'pass_weight_d3K_NLO_up', 'pass_weight_d3K_NLO_down', 'pass_weight_d1kappa_EW_up', 'pass_weight_d1kappa_EW_down', 'pass_weight_W_d2kappa_EW_up', 'pass_weight_W_d2kappa_EW_down', 'pass_weight_W_d3kappa_EW_up', 'pass_weight_W_d3kappa_EW_down', 'pass_weight_Z_d2kappa_EW_up', 'pass_weight_Z_d2kappa_EW_down', 'pass_weight_Z_d3kappa_EW_up', 'pass_weight_Z_d3kappa_EW_down', 'pass_weight_ele_id_up', 'pass_weight_ele_id_down', 'pass_weight_ele_reco_up', 'pass_weight_ele_reco_down', 'pass_weight_mu_isolation_up', 'pass_weight_mu_isolation_down', 'pass_weight_mu_id_up', 'pass_weight_mu_id_down', 'pass_weight_mu_trigger_iso_up', 'pass_weight_mu_trigger_iso_down', 'pass_weight_mu_trigger_noniso_up', 'pass_weight_mu_trigger_noniso_down', 'pass_weight_pileup_up', 'pass_weight_pileup_down', 'pass_weight_L1Prefiring_up', 'pass_weight_L1Prefiring_down', 'pass_weight_PSFSR_ZQQ_up', 'pass_weight_PSFSR_ZQQ_down', 'pass_weight_PSISR_ZQQ_up', 'pass_weight_PSISR_ZQQ_down', 'pass_weight_btagSFlightCorrelated_up', 'pass_weight_btagSFlightCorrelated_down', 'pass_weight_btagSFbcCorrelated_up', 'pass_weight_btagSFbcCorrelated_down', 'pass_weight_btagSFlight_up', 'pass_weight_btagSFlight_down', 'pass_weight_btagSFbc_up', 'pass_weight_btagSFbc_down', 'pass_JES_FlavorQCD_up', 'pass_JES_FlavorQCD_down', 'pass_JES_RelativeBal_up', 'pass_JES_RelativeBal_down', 'pass_JES_HF_up', 'pass_JES_HF_down', 'pass_JES_BBEC1_up', 'pass_JES_BBEC1_down', 'pass_JES_EC2_up', 'pass_JES_EC2_down', 'pass_JES_Absolute_up', 'pass_JES_Absolute_down', 'pass_JES_BBEC1_year_up', 'pass_JES_BBEC1_year_down', 'pass_JES_RelativeSample_year_up', 'pass_JES_RelativeSample_year_down', 'pass_JES_EC2_year_up', 'pass_JES_EC2_year_down', 'pass_JES_HF_year_up', 'pass_JES_HF_year_down', 'pass_JES_Absolute_year_up', 'pass_JES_Absolute_year_down', 'pass_JER_year_up', 'pass_JER_year_down', 'pass_UES_up', 'pass_UES_down'], growth=True, name='Systematic'),\n",
      "  StrCategory(['SR1'], growth=True, name='Region'),\n",
      "  Variable([40, 70, 108, 180], name='mass_observable', label='V reconstructed mass [GeV]'),\n",
      "  storage=Weight()) # Sum: WeightedSum(value=25.9065, variance=3.17816)\n"
     ]
    }
   ],
   "source": [
    "years = ['2016']\n",
    "\n",
    "outdir = 'templates'\n",
    "\n",
    "channels = 'mu','ele'\n",
    "\n",
    "with open(\"test.yaml\", \"r\") as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "if len(years) == 4:\n",
    "    save_as = \"Run2\"\n",
    "else:\n",
    "    save_as = \"_\".join(years)\n",
    "\n",
    "if len(channels) == 1:\n",
    "    save_as += f\"_{channels[0]}_\"\n",
    "\n",
    "os.system(f\"mkdir -p {outdir}\")\n",
    "\n",
    "hists = get_templates( years, channels, config[\"samples\"], config[\"samples_dir\"], config[\"regions_sel\"], config[\"model_path\"],)\n",
    "\n",
    "fix_neg_yields(hists)\n",
    "\n",
    "#with open(f\"{outdir}/hists_templates_{save_as}.pkl\", \"wb\") as fp:\n",
    "with open(f\"{outdir}/hists_templates_{save_as}_pass.pkl\", \"wb\") as fp:\n",
    "    print('hists', hists)\n",
    "    pkl.dump(hists, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e06fa-20da-4f40-96bd-8bce7251cc21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
